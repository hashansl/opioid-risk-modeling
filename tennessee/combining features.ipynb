{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features concatination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "gdf_2018 = gpd.read_file('./data/processed data/SVI2018 TN counties with death rate HepVu/SVI2018_TN_counties_with_death_rate_HepVu.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the folder names to a list without the folders that start with '.'\n",
    "variables = [f for f in os.listdir('./results/persistence images/percentiles/H0H1 np') if not f.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 47001\n",
      "Processing 47003\n",
      "Processing 47009\n",
      "Processing 47011\n",
      "Processing 47015\n",
      "Processing 47019\n",
      "Processing 47021\n",
      "Processing 47025\n",
      "Processing 47031\n",
      "Processing 47033\n",
      "Processing 47039\n",
      "Processing 47041\n",
      "Processing 47043\n",
      "Processing 47047\n",
      "Processing 47051\n",
      "Processing 47053\n",
      "Processing 47055\n",
      "Processing 47063\n",
      "Processing 47065\n",
      "Processing 47071\n",
      "Processing 47077\n",
      "Processing 47079\n",
      "Processing 47081\n",
      "Processing 47089\n",
      "Processing 47099\n",
      "Processing 47101\n",
      "Processing 47103\n",
      "Processing 47107\n",
      "Processing 47111\n",
      "Processing 47113\n",
      "Processing 47115\n",
      "Processing 47117\n",
      "Processing 47119\n",
      "Processing 47127\n",
      "Processing 47131\n",
      "Processing 47133\n",
      "Processing 47139\n",
      "Processing 47141\n",
      "Processing 47143\n",
      "Processing 47145\n",
      "Processing 47147\n",
      "Processing 47149\n",
      "Processing 47155\n",
      "Processing 47159\n",
      "Processing 47161\n",
      "Processing 47163\n",
      "Processing 47165\n",
      "Processing 47167\n",
      "Processing 47177\n",
      "Processing 47179\n",
      "Processing 47183\n",
      "Processing 47185\n",
      "Processing 47189\n",
      "Processing 47005\n",
      "Processing 47017\n",
      "Processing 47023\n",
      "Processing 47045\n",
      "Processing 47059\n",
      "Processing 47073\n",
      "Processing 47085\n",
      "Processing 47093\n",
      "Processing 47105\n",
      "Processing 47109\n",
      "Processing 47123\n",
      "Processing 47125\n",
      "Processing 47153\n",
      "Processing 47169\n",
      "Processing 47187\n",
      "Processing 47013\n",
      "Processing 47035\n",
      "Processing 47037\n",
      "Processing 47049\n",
      "Processing 47057\n",
      "Processing 47075\n",
      "Processing 47083\n",
      "Processing 47087\n",
      "Processing 47121\n",
      "Processing 47171\n",
      "Processing 47173\n",
      "Processing 47181\n",
      "Processing 47027\n",
      "Processing 47067\n",
      "Processing 47069\n",
      "Processing 47091\n",
      "Processing 47135\n",
      "Processing 47137\n",
      "Processing 47151\n",
      "Processing 47157\n",
      "Processing 47175\n",
      "Processing 47029\n",
      "Processing 47129\n",
      "Processing 47007\n",
      "Processing 47061\n",
      "Processing 47097\n",
      "Processing 47095\n"
     ]
    }
   ],
   "source": [
    "for fips_code in gdf_2018['FIPS']:\n",
    "\n",
    "    print(f'Processing {fips_code}')\n",
    "\n",
    "    # Load the data\n",
    "    peristence_image_1 = np.load(f'./results/persistence images/percentiles/H0H1 np/{variables[0]}/{fips_code}.npy')\n",
    "    peristence_image_2 = np.load(f'./results/persistence images/percentiles/H0H1 np/{variables[1]}/{fips_code}.npy')\n",
    "    peristence_image_3 = np.load(f'./results/persistence images/percentiles/H0H1 np/{variables[2]}/{fips_code}.npy')\n",
    "    # peristence_image_4 = np.load(f'./results/persistence images/percentiles/H0H1 np/{variables[3]}/{fips_code}.npy')\n",
    "    # peristence_image_5 = np.load(f'./results/persistence images/percentiles/H0H1 np/{variables[4]}/{fips_code}.npy')\n",
    "\n",
    "    # # print persistence image shapes \n",
    "    # print(peristence_image_1.shape)\n",
    "    # print(peristence_image_2.shape)\n",
    "    # print(peristence_image_3.shape)\n",
    "    # print(peristence_image_4.shape)\n",
    "    # print(peristence_image_5.shape)\n",
    "\n",
    "    # Concatenate the persistence images\n",
    "    #combined_matrix = np.stack((peristence_image_1, peristence_image_2, peristence_image_3, peristence_image_4, peristence_image_5), axis=-1)\n",
    "    combined_matrix = np.stack((peristence_image_1, peristence_image_2, peristence_image_3), axis=-1)\n",
    "\n",
    "    # save the persistence image\n",
    "    np.save(f'./results/persistence images/percentiles/H0H1-3 channels/{fips_code}', combined_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
